{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "colab_nb.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "wRIOFvjsCjfJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qOl4zsGjCkU-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LGUkbPomDl45",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "28f30fa8-eef7-4997-b486-af3edfa89d56"
      },
      "source": [
        "%cd drive/My Drive/drqa_doc_reader"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/drqa_doc_reader\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7nHoqwmQDszp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "983d4384-24d3-4e13-f5d4-36558de51476"
      },
      "source": [
        "pwd"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/drive/My Drive/drqa_doc_reader'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0TUMojkcD0z5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0018d4ad-d141-498d-bc87-66c1745e81f4"
      },
      "source": [
        "#!pip install ujson"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: ujson in /usr/local/lib/python3.6/dist-packages (1.35)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M5lFNcE_Dvfi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#!python setup.py --train_url=\"./data/train-v1.1.json\" --dev_url=\".data/dev-v1.1.json\" --glove_url=\".data/glove.840B.300d.zip\" --include_test_examples=False"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I56OUqUJH2WW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "4321e9bb-09ac-4624-cf09-631e2ff50d9e"
      },
      "source": [
        "import json\n",
        "import numpy as np\n",
        "import torch\n",
        "from model import StanfAR\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.utils import data\n",
        "import time\n",
        "\n",
        "'''\n",
        "steps - \n",
        "1. load data\n",
        "2. preprocess\n",
        "3. train\n",
        "4. tensorboard / evaluation on dev\n",
        "5. saving/checkpointing/loading model\n",
        "6. predict function\n",
        "7. web app\n",
        "8. packaging, code quality testing, etc.\n",
        "'''\n",
        "#%%"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nsteps - \\n1. load data\\n2. preprocess\\n3. train\\n4. tensorboard / evaluation on dev\\n5. saving/checkpointing/loading model\\n6. predict function\\n7. web app\\n8. packaging, code quality testing, etc.\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BJBl-eRGIiA7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_json_file(path):\n",
        "    with open(path) as file:\n",
        "        out = json.load(file)\n",
        "    return out\n",
        "\n",
        "\n",
        "def load_npz_file(path):\n",
        "    return np.load(path)\n",
        "\n",
        "\n",
        "def load_files(path):\n",
        "    word2idx = load_json_file(path + \"/word2idx.json\")\n",
        "    word_emb = load_json_file(path + \"/word_emb.json\")\n",
        "\n",
        "    train_data = load_npz_file(path + \"/train.npz\")\n",
        "    dev_data = load_npz_file(path + \"/dev.npz\")\n",
        "\n",
        "    idx2word = {i:j for j,i in word2idx.items()}\n",
        "\n",
        "    return word2idx, idx2word, word_emb, train_data, dev_data\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_bOb5VjXIkux",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#%% loading\n",
        "word2idx, idx2word, word_emb, train_data, dev_data = load_files(path='data')\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_AARxVbOJgP_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JOSffrhvJg1Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nnIsQZkwIro7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#%% preprocessing\n",
        "train_q = torch.LongTensor(train_data['ques_idxs']).to(device)\n",
        "train_c = torch.LongTensor(train_data['context_idxs']).to(device)\n",
        "\n",
        "labels1 = torch.as_tensor(train_data['y1s']).to(device)\n",
        "labels2 = torch.as_tensor(train_data['y2s']).to(device)\n",
        "\n",
        "word_emb = torch.as_tensor(word_emb).to(device)\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WgJ6dpaSIo3v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#%%\n",
        "class Dataset(data.Dataset):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.data = (train_q, train_c, labels1, labels2)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data[0])\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        query = self.data[0][idx]\n",
        "        ctx = self.data[1][idx]\n",
        "        y1 = self.data[2][idx]\n",
        "        y2 = self.data[3][idx]\n",
        "\n",
        "        return query, ctx, y1, y2\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FA0QjDKFIs25",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#%%\n",
        "df = torch.utils.data.DataLoader(Dataset(), batch_size=32)\n",
        "\n",
        "\n",
        "#%% training loop\n",
        "torch.set_grad_enabled(True)\n",
        "\n",
        "network = StanfAR(word_emb, 32).to(device)\n",
        "\n",
        "optimizer = optim.Adamax(network.parameters(), lr=0.01)\n",
        "\n",
        "total_loss = 0\n",
        "total_correct = 0\n",
        "\n",
        "i = 0\n",
        "num_epochs = 500\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tviyp1S1IuLi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#%%\n",
        "\n",
        "for j in range(num_epochs):\n",
        "  i=0\n",
        "  acc = []\n",
        "  tic = time.time()\n",
        "  for batch in df:  # Get Batch\n",
        "      i+=1\n",
        "      query, context, y1, y2 = batch\n",
        "      #print(f\"Query input shape: {query.shape}\\nContext Input shape: {context.shape}\\ny1 shape: {y1.shape}\\ny2 shape: {y2.shape}\")\n",
        "      if query.shape[0] != 32:\n",
        "          break\n",
        "\n",
        "      preds = network(query, context)  # Pass Batch\n",
        "\n",
        "      loss = (F.cross_entropy(preds[0], y1))+(F.cross_entropy(preds[1], y2))\n",
        "      #print(f\"loss: {loss.shape}\")\n",
        "\n",
        "      optimizer.zero_grad()\n",
        "      loss.backward()  # Calculate Gradients\n",
        "      optimizer.step()  # Update Weights\n",
        "\n",
        "      total_loss += loss.item()\n",
        "      acc.append((preds[0].argmax(dim=1)==y1).sum())\n",
        "      \n",
        "  toc = time.time()\n",
        "  print(f\"epoch: {j+1}\\naccuracy_est_batch: {np.mean(acc[-100:])}\\ntime taken: {toc-tic}\")\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eNnss-4iIzWi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#%%\n",
        "print(\n",
        "    \"epoch:\", 0,\n",
        "    \"total_correct:\", total_correct,\n",
        "    \"loss:\", total_loss\n",
        ")\n",
        "\n",
        "\n",
        "\n",
        "#%%\n",
        "model = StanfAR(word_emb, 32)\n",
        "sample_data_q, sample_data_c  = next(iter(train_loader_q)), next(iter(train_loader_c))\n",
        "\n",
        "out = model(sample_data_q, sample_data_c)\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}